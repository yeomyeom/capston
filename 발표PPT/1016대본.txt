#2
목차는 이것입니다.

#3
저희는 구글 크롬 확장 프로그램을 이용하여 서버로 파싱해야하는 URL을 넘깁니다.
그 다음 전처리를 konlpy를 이용하여 처리하고 광고성 판단 알고리즘으로 특징을 추출하고
다시 크롬 확장프로그램을 통해 사용자에게 결과를 보여줍니다.

#4 
konlpy로 형태소나눔

#5
단순히 한글 형태소 뿐만이 아니라 숫자, 영어, 한자, ‘!’ 등 까지 분류해주었다.

#7
이러한 결과를 출력하게 됩니다.

#6
다음으로 저희가 생각하는 광고성 판단 알고리즘의 특징 7가지 입니다. 물론 계속 논문을 
찾아보면서 특징 갯수를 늘려갈 것입니다.
긍정어 비율
부정어 비율
감정 점수: (긍-부) / 전체단어수 즉 얼마나 긍정적인가?
단어 중요도 : TF-IDF
외부 http 링크 : 광고 회사 링크가 있는지 확인
네이버 스티커 종류를 판별하여 광고에서 자주 쓰이는 스티커가 있는지 확인
제목과 관련이 없는 내용이 자주 나오는지를 확인해 본다.

#8
TF-IDF 예시 입니다. 지금 있는 표는 각 document 당 해당 단어가 몇번 나왔는지 적혀있습니다.
여기에서 TF-IDF 는 다음과 같은 연산을 진행하고

#9
document 3을 보면 seoul city 두 단어 점수가 높은데 그 이유는 school은 doc2에서 나왔지만 seoul과 city는 doc3에만 나와서 doc1 2 3 4 중 doc3을 구분할 수 있게 해주는 단어는 seoul city임을 알 수 있습니다.

#10 
1. 블로그 크롤링 시 어쩔 수 없이 나오는 단어들이 있는데(특히 ui쪽) 다행이도 tf-idf에서 낮은 점수를 받고 걸려진다.
2. 문제점이라 하면, idf가 문서 전체를 분모로 잡고 평가하는 것이기에 표본이 커질 수록 속도가 느리다는 정도이다.
3. 현재 konlpy에서 출력된 결과값과 감정점수 부여 프로그램 속 감정사전의 단어와 호환성이 떨어진다.

#11
광고성?∩ 비광고성의 원소 수가 생각보다 적어서 실제 사용시 해당 원소에 걸리는 블로그 글이 많지는 않을 거라 예상된다.
중간고사 이후 실제 대용량의 블로그 데이터로 전처리 했을 경우에도 원소 수가 적을 경우 카테고리 분류 시 교집합이 아닌 합집합, 즉 단순 tfidf 데이터 중 수치가 높은 데이터만을 뽑아 카테고리 분류에 쓰일 계획이다.

#12
저희는 블로그 글의 분류를 위해 3가지 아이디어를 제시한 바 있습니다. 그 구현을 SVM, 지지 벡터 머신을 통해 하려고 합니다. 텍스트 클래시피케이션을 위해 사용되는 다른 알고리즘, kmean이 아닌 SVM을 사용하는 이유는 다음과 같습니다.
첫 째로 kmean의 경우 통계적인 접근을 통해 클래시피케이션이 이루어지므로 학습 데이터가 충분히 크지 않으면 잘 작동하지 않습니다. 반면에 SVM은 하이퍼플레인을 이용해 작동하기 때문에 상대적으로 적은 데이터에서도 잘 작동한다는 장점이 있습니다.
두 번째로 kmean의 경우 아웃라이어 데이터에 취약하다는 단점이 있습니다.

#13
전에 조교님이 지적하셨던 사다리 팀의 경우 kmean을 통해 클러스터링을 진행하였다고 밝히고 있습니다. 또한 "현재, v1.0 사다리는 사용자에게 머신러닝 결과와 혼동의 여부를 줄 수 있어, 신뢰성이 있는 블로그가 많이 포함되어있는 집단 / 신뢰성이 떨어지는 블로그가 많이 포함되어있는 집단으로 나누지는 않았습니다. 대신, type의 블로그로 나누어 결과와 해석을 제시합니다." 라는 말을 통해 자신들의 머신러닝 결과가 신뢰성에 대해 나눈 결과와 일치하지 않음을 암시하고 있습니다. 따라서 저희는 접근법을 SVM으로 바꾸어서 신뢰성을 담보할 수 있는 요소들을 차용하여 이러한 문제를 해결하고자 합니다

#14
그 외에도 다른 여러 접근법이 있습니다만 최종적으로 저희는 SVM을 사용하는 것이 가장 합당하다고 판단하였습니다.
우선 딥러닝, 신경망 기법은 지나치게 비용이 크고, 고작 수만개의 글로 잘 작동한다는 보장이 없어 배재하였습니다.
그리고 나이브 베이지안 분류기는 kMean과 비슷한 이유로 부적절하다고 판단하였습니다.
에이다부스트도 좋은 알고리즘입니다만 노이즈에 민감하고 오버피팅이 잘 일어난다는 점으로 인해 중구난방인 블로그 글의 분류에 적합하지 않다고 생각하여 제외했습니다.

#15
SVM을 구현하기 위해 어떤 피쳐들을 사용할 것인지 조사해본 결과, 이전의 연구를 참고해 카이제곱을 사용하기로 하였고, 이전 발표에서 말씀드린 대로 긍부정어의 비율과 TFIDF를 이용합니다

#16
SVM 구현의 세부 사항입니다. 파이썬 기반으로 사이킷 런 라이브러리를 이용하려고 합니다. 같은 파이썬을 통해 플라스크를 구동하므로 손쉬운 연동이 가능할것입니다. 흔히 SVM을 사용할 때 커널 트릭을 이용하지만 이전 연구에 의하여, 우선은 선형 분류만으로도 충분하다고 생각하고 진행하려고 합니다. 혹 잘 작동하지 않는다면 그 때 커널을 적용하려고 합니다.

#17
저희 스케줄에 서버 개발과 감정 단어 사전 개선이 2가지 새로 생겼습니다. 

#18
중간고사 이후 저희가 계획하고 있는 스케줄 입니다.

#19
감사합니다. 질문 안받습니다.