저저번에 각 결과별로 정확한 수치를 요구하여서 실험을 다시 진행

처음 한 실험
데이터 개수 649개에서 90퍼센트를 학습용, 10퍼센트를 테스트용으로 무작위 분할
사용한 특성은 각 문서 별로 갖고 있는 tf-idf 벡터를 카이제곱 상위에 해당하는 단어들만 추출한 것 -> 이렇게 해주는 이유는 카이제곱이 높은 벡터의 성분, 즉 단어가 카테고리의 특징 여기서는 광고성/비광고성을 잘 보여주기 때문
각 모델을 평가하는 점수는 분할해둔 테스트셋에 대해 예측을 하여 얼마나 잘 맞는가를 백분율로 표현하는 것
처음한 실험은 그 데이터가 많지 않아 무작위 분할로 정해진 테스트 셋에 결과가 바뀌는 문제가 있음

카이제곱 상위 100개에 대해 진행한 결과
카이제곱 상위 1000개에 대해 진행한 결과

실험을 진행할 때마다 값이 계속 크게 바뀌므로 별로 신뢰할 만한 값은 아님

두 번째 실험
샘플 데이터셋의 크기가 1449개로 늘었음. 방법은 전과 동일

두 번째 실험에 앞서 카이제곱 커팅의 개수를 몇개로 하는 것이 맞는가 실험을 해본 결과 10개에서 200개 사이에서 최적의 결과를 보이고 그보다 적거나 많을 때에는 상대적으로 좋지 않은 결과를 보이므로 10개와 100개로 실험해보았음

실험결과
성능: SVM 신경망 에이다 랜덤포레스트 결정트리
시간: 결정트리 SVM 신경망 랜덤포레스트 에이다
순으로 뛰어났음 -> SVM 유용함

이 경우에도 실행할 때마다 값이 바뀌긴 하지만 크게 값이 바뀌진 않고 대소관계가 유지되는 일관성을 보이므로 유의미한 결과라고 생각됨
